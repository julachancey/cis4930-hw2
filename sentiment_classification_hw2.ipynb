{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c32bea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db2ec3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7ff97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1048575\n",
      "Number of rows: 359\n"
     ]
    }
   ],
   "source": [
    "# Check the size of the dataset\n",
    "print('Number of rows:', len(df))\n",
    "print('Number of rows:', len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce1e39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    800000\n",
      "1    248575\n",
      "Name: Sentiment, dtype: int64\n",
      "1    182\n",
      "0    177\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the sentiment distribution of the dataset\n",
    "print(df['Sentiment'].value_counts())\n",
    "print(test_df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ac3b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index        0\n",
      "Sentiment    0\n",
      "Text         0\n",
      "dtype: int64\n",
      "Index        0\n",
      "Sentiment    0\n",
      "Text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any missing values\n",
    "print(df.isnull().sum())\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebb17acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/julia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Text Preprocessing\n",
    "import re\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove numbers and special characters\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Split the text into individual words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Remove stop words from the text\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word.casefold() not in stop_words]\n",
    "\n",
    "    # Join the filtered words back into a single string\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "    return filtered_text\n",
    "\n",
    "# Apply the preprocessing function to the text column\n",
    "df['text'] = df['Text'].apply(clean_text)\n",
    "test_df['text'] = test_df['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linguistic Feature Extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b8e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words\n",
    "count_vect = CountVectorizer()\n",
    "bow = count_vect.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf = tfidf_vect.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc288be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "import numpy as np\n",
    "sentences = [text.split() for text in df['text']]\n",
    "word2vec_model = Word2Vec(sentences, window=5, min_count=1)\n",
    "word2vec_X = []\n",
    "for sentence in sentences:\n",
    "    sentence_vec = np.zeros((100,))\n",
    "    for word in sentence:\n",
    "        if word in word2vec_model.wv:\n",
    "            sentence_vec += word2vec_model.wv[word]\n",
    "    word2vec_X.append(sentence_vec)\n",
    "word2vec_X = np.array(word2vec_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b566a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Classification Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbfac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2e56e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(bow, df['Sentiment'], test_size=0.2, random_state=42)\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(tfidf, df['Sentiment'], test_size=0.2, random_state=42)\n",
    "X_train_word2vec, X_test_word2vec, y_train_word2vec, y_test_word2vec = train_test_split(word2vec_X, df['Sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2938a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr_bow = LogisticRegression(max_iter=1000000)\n",
    "lr_bow.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "lr_tfidf = LogisticRegression(max_iter=1000000)\n",
    "lr_tfidf.fit(X_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537226ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM classifier\n",
    "svm_bow = SVC()\n",
    "svm_bow.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "svm_tfidf = SVC()\n",
    "svm_tfidf.fit(X_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c878940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes classifier\n",
    "nbc_bow = MultinomialNB()\n",
    "nbc_bow.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "nbc_tfidf = MultinomialNB()\n",
    "nbc_tfidf.fit(X_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61eb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest classifier\n",
    "rfc_bow = RandomForestClassifier()\n",
    "rfc_bow.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "rfc_tfidf = RandomForestClassifier()\n",
    "rfc_tfidf.fit(X_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe0156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# create MLP model\n",
    "mlp_model = Sequential()\n",
    "mlp_model.add(Dense(128, activation='relu', input_dim=X_train_w2v.shape[1]))\n",
    "mlp_model.add(Dropout(0.2))\n",
    "mlp_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "mlp_model.fit(X_train_word2vec, y_train_word2vec, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# LSTM model\n",
    "from keras.layers import LSTM, Embedding\n",
    "\n",
    "# create LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=max_length))\n",
    "lstm_model.add(LSTM(units=64))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "lstm_model.fit(X_train_word2vec, y_train_word2vec, epochs=10, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706aa4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_lr_bow = lr_bow.predict(X_test_bow)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "print('Logistic Regression Bag of Words')\n",
    "print('Accuracy:', accuracy_score(y_test_bow, y_pred_lr_bow))\n",
    "print('Precision:', precision_score(y_test_bow, y_pred_lr_bow, average='weighted'))\n",
    "print('Recall:', recall_score(y_test_bow, y_pred_lr_bow, average='weighted'))\n",
    "print('F1-score:', f1_score(y_test_bow, y_pred_lr_bow, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ce908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred_lr_tfidf = lr_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "print('Logistic Regression TF-IDF')\n",
    "print('Accuracy:', accuracy_score(y_test_tfidf, y_pred_lr_tfidf))\n",
    "print('Precision:', precision_score(y_test_tfidf, y_pred_lr_tfidf, average='weighted'))\n",
    "print('Recall:', recall_score(y_test_tfidf, y_pred_lr_tfidf, average='weighted'))\n",
    "print('F1-score:', f1_score(y_test_tfidf, y_pred_lr_tfidf, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3306c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred_svm_bow = svm_bow.predict(X_test_bow)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "print('SVM classifier Bag of Words')\n",
    "print('Accuracy:', accuracy_score(y_test_bow, y_pred_svm_bow))\n",
    "print('Precision:', precision_score(y_test_bow, y_pred_svm_bow, average='weighted'))\n",
    "print('Recall:', recall_score(y_test_bow, y_pred_svm_bow, average='weighted'))\n",
    "print('F1-score:', f1_score(y_test_bow, y_pred_svm_bow, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0832286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred_svm_tfidf = svm_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "print('SVM classifier TF-IDF')\n",
    "print('Accuracy:', accuracy_score(y_test_tfidf, y_pred_svm_tfidf))\n",
    "print('Precision:', precision_score(y_test_tfidf, y_pred_svm_tfidf, average='weighted'))\n",
    "print('Recall:', recall_score(y_test_tfidf, y_pred_svm_tfidf, average='weighted'))\n",
    "print('F1-score:', f1_score(y_test_tfidf, y_pred_svm_tfidf, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dd5ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred_nbc_bow = nbc_bow.predict(X_test_bow)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "print('Naive Bayes Bag of Words')\n",
    "print('Accuracy:', accuracy_score(y_test_bow, y_pred_nbc_bow))\n",
    "print('Precision:', precision_score(y_test_bow, y_pred_nbc_bow, average='weighted'))\n",
    "print('Recall:', recall_score(y_test_bow, y_pred_nbc_bow, average='weighted'))\n",
    "print('F1-score:', f1_score(y_test_bow, y_pred_nbc_bow, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b832db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred_nbc_tfidf = nbc_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "print('Naive Bayes TF-IDF')\n",
    "print('Accuracy:', accuracy_score(y_test_tfidf, y_pred_nbc_tfidf))\n",
    "print('Precision:', precision_score(y_test_tfidf, y_pred_nbc_tfidf, average='weighted'))\n",
    "print('Recall:', recall_score(y_test_tfidf, y_pred_nbc_tfidf, average='weighted'))\n",
    "print('F1-score:', f1_score(y_test_tfidf, y_pred_nbc_tfidf, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9039e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred_rfc_bow = rfc_bow.predict(X_test_bow)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "print('Random Forest Bag of Words')\n",
    "print('Accuracy:', accuracy_score(y_test_bow, y_pred_rfc_bow))\n",
    "print('Precision:', precision_score(y_test_bow, y_pred_rfc_bow, average='weighted'))\n",
    "print('Recall:', recall_score(y_test_bow, y_pred_rfc_bow, average='weighted'))\n",
    "print('F1-score:', f1_score(y_test_bow, y_pred_rfc_bow, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred_rfc_tfidf = rfc_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "print('Random Forest TF-IDF')\n",
    "print('Accuracy:', accuracy_score(y_test_tfidf, y_pred_rfc_tfidf))\n",
    "print('Precision:', precision_score(y_test_tfidf, y_pred_rfc_tfidf, average='weighted'))\n",
    "print('Recall:', recall_score(y_test_tfidf, y_pred_rfc_tfidf, average='weighted'))\n",
    "print('F1-score:', f1_score(y_test_tfidf, y_pred_rfc_tfidf, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf266f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred_mlp = mlp_model.predict(X_test_word2vec)\n",
    "y_pred_lstm = lstm_model.predict_classes(X_test_word2vec)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "print('MLP - multilayer perceptron - Word2Vec')\n",
    "print('Accuracy:', accuracy_score(y_test_word2vec, y_pred_mlp))\n",
    "print('Precision:', precision_score(y_test_word2vec, y_pred_mlp, average='weighted'))\n",
    "print('Recall:', recall_score(y_test_word2vec, y_pred_mlp, average='weighted'))\n",
    "print('F1-score:', f1_score(y_test_word2vec, y_pred_mlp, average='weighted'))\n",
    "\n",
    "print('LSTM - long short-term memory - Word2Vec')\n",
    "print('Accuracy:', accuracy_score(y_test_word2vec, y_pred_lstm))\n",
    "print('Precision:', precision_score(y_test_word2vec, y_pred_lstm, average='weighted'))\n",
    "print('Recall:', recall_score(y_test_word2vec, y_pred_lstm, average='weighted'))\n",
    "print('F1-score:', f1_score(y_test_word2vec, y_pred_lstm, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227cfc18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
